---
permalink: /
title: "Yejin Son"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I'm Yejin Son, a PhD student in Artificial Intelligence at the [Yonsei University](https://yonsei.ac.kr), [MIRLAB](https://mirlab.yonsei.ac.kr/) advised by [Youngjae Yu](https://yj-yu.github.io/home/). 
I earned a B.S. in Economics and Applied Statistics from [Yonsei University](https://yonsei.ac.kr) in 2023.

## Research Interests

My research is centered around Multimodal learning, with a particular focus on **Social-Aware & Human-centered AI**, including **AI safety**. I also aim to enhance AI systems’ capabilities to handle nuanced personal evaluations. 

## Publications
<div style="display: flex; gap: 16px; align-items: center; margin-bottom: 32px;">
  <img src="/images/glyphdecode.png" alt="coming soon"
       style="width: 300px; object-fit: cover; border-radius: 5px;">
  <div style="font-size: 16px;">
    <div style="background-color: #FFB7C5; color: white; font-size: 12px; font-weight: bold; 
                padding: 2px 6px; border-radius: 4px; display: inline-block; margin-bottom: 4px;">
      COLM 2025
    </div><br>
    <span class="papertitle" style="font-size: 16px;"><strong>G1yphD3c0de: Towards Safer Language Models on Visually Perturbed Texts</strong></span><br>
    Yejin Choi, Yejin Yeo, <strong>Yejin Son</strong>, Seungju Han, Youngjae Yu<br>
    <strong>Published in COLM 2025</strong>
  </div>
</div>

<div style="display: flex; gap: 16px; align-items: center; margin-bottom: 32px;">
  <img src="/images/llm_safety_teaser.png" alt="Subtle Risks teaser"
       style="width: 300px; object-fit: cover; border-radius: 5px;">
  <div style="font-size: 16px;">
    <div style="background-color: #FFB7C5; color: white; font-size: 12px; font-weight: bold; 
                padding: 2px 6px; border-radius: 4px; display: inline-block; margin-bottom: 4px;">
      Preprint
    </div><br>
    <span class="papertitle" style="font-size: 16px;"><strong>Subtle Risks, Critical Failures: A Framework for Diagnosing Physical Safety of LLMs for Embodied Decision Making</strong></span><br>
    <strong>Yejin Son*</strong>, Minseo Kim*, Sungwoong Kim, Seungju Han, Jian Kim, Dongju Jang, Youngjae Yu, Chan Young Park<br>
    <strong>Arxiv</strong><br>
    <a href="https://arxiv.org/abs/2505.19933">[Paper]</a>
  </div>
</div>

<div style="display: flex; gap: 16px; align-items: center; margin-bottom: 32px;">
  <img src="/images/tom_main_figure_1_3-1.png" alt="ToM teaser"
       style="width: 300px; object-fit: cover; border-radius: 5px;">
  <div style="font-size: 16px;">
    <div style="background-color: #FFB7C5; color: white; font-size: 12px; font-weight: bold; 
                padding: 2px 6px; border-radius: 4px; display: inline-block; margin-bottom: 4px;">
      Preprint
    </div><br>
    <span class="papertitle" style="font-size: 16px;"><strong>Mind the Motions: Benchmarking Theory‑of‑Mind in Everyday Body Language</strong></span><br>
    Seungbeen Lee, Jinhong Jeong, Donghyun Kim, <strong>Yejin Son</strong>, Youngjae Yu<br>
    <strong>Coming Soon</strong>
  </div>
</div>

<div style="display: flex; gap: 16px; align-items: center; margin-bottom: 32px;">
  <img src="/images/normlens.jpg" alt="Book Norms teaser"
       style="width: 300px; object-fit: cover; border-radius: 5px;">
  <div style="font-size: 16px;">
    <div style="background-color: #FFB7C5; color: white; font-size: 12px; font-weight: bold; 
                padding: 2px 6px; border-radius: 4px; display: inline-block; margin-bottom: 4px;">
      EMNLP 2023
    </div><br>
    <span class="papertitle" style="font-size: 16px;"><strong>Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms</strong></span><br>
    Seungju Han, Junhyeok Kim, Jack Hessel, Liwei Jiang, Jiwan Chung, <strong>Yejin Son</strong>, Yejin Choi, Youngjae Yu<br>
    <strong>Published in EMNLP 2023</strong><br>
    <a href="https://arxiv.org/abs/2310.10418">[Paper]</a>
  </div>
</div>



<p>Website last updated: July 8, 2025</p>
